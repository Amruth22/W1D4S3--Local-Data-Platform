"""
Comprehensive Unit Tests for Weather Station Data Logger
Tests LRU cache, connection pooling, time-series data, and analytics functionality
"""

import unittest
import requests
import json
import time
import threading
from datetime import datetime, timedelta
from typing import List, Dict, Any
import random

class WeatherStationTestCase(unittest.TestCase):
    """Unit tests for the Weather Station Data Logger"""
    
    @classmethod
    def setUpClass(cls):
        """Set up test configuration - runs once before all tests"""
        cls.base_url = "http://localhost:8000"
        cls.test_sensors = ["test_outdoor", "test_indoor", "test_greenhouse"]
        
        print(f"\nüå°Ô∏è Starting Weather Station Unit Tests")
        print(f"üìç Testing API at: {cls.base_url}")
        
    def setUp(self):
        """Set up before each test method"""
        # Clear existing data for clean tests
        try:
            response = requests.delete(f"{self.base_url}/readings/clear")
            if response.status_code == 200:
                print(f"   üßπ Test data cleared")
        except:
            pass
        
        # Small delay to ensure cleanup
        time.sleep(0.05)
        
    def tearDown(self):
        """Clean up after each test method"""
        pass
    
    def make_request(self, method: str, endpoint: str, data: dict = None, params: dict = None) -> requests.Response:
        """Helper method to make HTTP requests"""
        url = f"{self.base_url}{endpoint}"
        
        try:
            if method.upper() == "GET":
                return requests.get(url, params=params)
            elif method.upper() == "POST":
                return requests.post(url, json=data)
            elif method.upper() == "DELETE":
                return requests.delete(url)
        except requests.exceptions.ConnectionError:
            self.fail("Could not connect to Weather Station API. Make sure it's running on http://localhost:8000")
    
    def submit_reading(self, temperature: float, sensor_id: str, timestamp: datetime = None) -> requests.Response:
        """Helper method to submit a temperature reading"""
        reading_data = {
            "temperature": temperature,
            "sensor_id": sensor_id
        }
        if timestamp:
            reading_data["timestamp"] = timestamp.isoformat()
        
        return self.make_request("POST", "/readings", reading_data)
    
    def get_system_status(self) -> Dict[str, Any]:
        """Helper method to get system status"""
        response = self.make_request("GET", "/status")
        self.assertEqual(response.status_code, 200)
        return response.json()
    
    # Test 1: Data Storage and Retrieval
    def test_01_data_storage_and_retrieval(self):
        """Test temperature reading storage and retrieval functionality"""
        print("\n1Ô∏è‚É£ Testing data storage and retrieval...")
        
        # Test data
        test_readings = [
            {"temp": 22.5, "sensor": "outdoor_sensor"},
            {"temp": 24.1, "sensor": "indoor_sensor"},
            {"temp": 21.8, "sensor": "greenhouse_sensor"},
            {"temp": 23.2, "sensor": "outdoor_sensor"},
            {"temp": 25.0, "sensor": "indoor_sensor"},
        ]
        
        # Submit readings
        for reading in test_readings:
            response = self.submit_reading(reading["temp"], reading["sensor"])
            self.assertEqual(response.status_code, 200)
            
            result = response.json()
            self.assertEqual(result["temperature"], reading["temp"])
            self.assertEqual(result["sensor_id"], reading["sensor"])
            self.assertIn("timestamp", result)
            print(f"   ‚úÖ Stored: {reading['sensor']} - {reading['temp']}¬∞C")
        
        # Wait for background processing
        time.sleep(0.2)
        
        # Retrieve recent readings
        response = self.make_request("GET", "/readings/recent", params={"limit": 5})
        self.assertEqual(response.status_code, 200)
        
        readings = response.json()
        self.assertEqual(len(readings), 5)
        
        # Verify data structure
        for reading in readings:
            self.assertIn("timestamp", reading)
            self.assertIn("temperature", reading)
            self.assertIn("sensor_id", reading)
            self.assertIsInstance(reading["temperature"], (int, float))
            self.assertIsInstance(reading["sensor_id"], str)
        
        # Verify readings are in reverse chronological order (most recent first)
        timestamps = [datetime.fromisoformat(r["timestamp"].replace('Z', '+00:00')) for r in readings]
        self.assertEqual(timestamps, sorted(timestamps, reverse=True))
        
        print(f"   ‚úÖ Retrieved {len(readings)} readings in correct order")
        
        # Verify system status reflects stored data
        status = self.get_system_status()
        self.assertGreaterEqual(status["database"]["total_readings"], 5)
        print(f"   ‚úÖ Database contains {status['database']['total_readings']} total readings")
    
    # Test 2: LRU Cache Functionality
    def test_02_lru_cache_functionality(self):
        """Test LRU cache capacity, eviction, and functionality"""
        print("\n2Ô∏è‚É£ Testing LRU cache functionality...")
        
        # Get initial cache status
        initial_status = self.get_system_status()
        initial_cache_size = initial_status["cache"]["size"]
        cache_capacity = initial_status["cache"]["capacity"]
        
        self.assertEqual(cache_capacity, 100)
        print(f"   üìä Cache capacity: {cache_capacity}, initial size: {initial_cache_size}")
        
        # Submit readings to test cache functionality
        readings_to_submit = 5  # Minimal readings to test cache behavior
        
        print(f"   üìù Submitting {readings_to_submit} readings to test cache...")
        
        for i in range(readings_to_submit):
            temperature = 20 + (i * 2)  # Simple temperature progression
            sensor_id = f"cache_sensor_{i + 1}"
            
            response = self.submit_reading(temperature, sensor_id)
            self.assertEqual(response.status_code, 200)
        
        # Minimal wait for background processing
        time.sleep(0.2)
        
        # Check final cache status
        final_status = self.get_system_status()
        final_cache_size = final_status["cache"]["size"]
        total_readings = final_status["database"]["total_readings"]
        
        # Verify LRU behavior
        self.assertLessEqual(final_cache_size, cache_capacity)  # Should not exceed capacity
        self.assertGreaterEqual(total_readings, readings_to_submit)  # All readings stored in DB
        
        print(f"   ‚úÖ Cache size: {final_cache_size}/{cache_capacity} (within capacity)")
        print(f"   ‚úÖ Database total: {total_readings} (all readings stored)")
        print(f"   ‚úÖ Cache functionality verified: readings stored and cached properly")
        
        # Verify cache contains most recent readings
        response = self.make_request("GET", "/readings/recent", params={"limit": 10})
        self.assertEqual(response.status_code, 200)
        recent_readings = response.json()
        
        # Most recent readings should be available
        self.assertGreater(len(recent_readings), 0)
        print(f"   ‚úÖ Most recent readings still accessible: {len(recent_readings)} readings")
    
    # Test 3: Cache-First Analytics
    def test_03_cache_first_analytics(self):
        """Test cache-first strategy for hourly average calculations"""
        print("\n3Ô∏è‚É£ Testing cache-first analytics...")
        
        # Test scenario 1: Insufficient cache data (should use database)
        print("   üìä Testing with insufficient cache data...")
        
        # Submit only a few readings
        few_readings = [
            {"temp": 20.0, "sensor": "analytics_sensor_1"},
            {"temp": 22.0, "sensor": "analytics_sensor_2"},
            {"temp": 24.0, "sensor": "analytics_sensor_3"},
        ]
        
        for reading in few_readings:
            response = self.submit_reading(reading["temp"], reading["sensor"])
            self.assertEqual(response.status_code, 200)
        
        time.sleep(0.3)  # Wait for processing
        
        # Get hourly average
        response = self.make_request("GET", "/analytics/average-hour")
        
        if response.status_code == 200:
            analytics_data = response.json()
            self.assertIn("average_temperature", analytics_data)
            self.assertIn("data_source", analytics_data)
            self.assertIn("readings_count", analytics_data)
            
            # With few readings, should use database
            expected_source = "database"  # Not enough for cache
            print(f"   ‚úÖ Data source: {analytics_data['data_source']} (expected: {expected_source})")
            print(f"   ‚úÖ Average temperature: {analytics_data['average_temperature']}¬∞C")
            print(f"   ‚úÖ Readings count: {analytics_data['readings_count']}")
        
        # Test scenario 2: Sufficient cache data (should use cache)
        print("   üìä Testing with sufficient cache data...")
        
        # Generate recent readings for cache analytics
        
        for i in range(8):  # Sufficient readings for cache strategy
            temperature = 22 + (i * 0.5)  # Simple progression
            sensor_id = f"analytics_sensor_{i + 1}"
            
            response = self.submit_reading(temperature, sensor_id)
            self.assertEqual(response.status_code, 200)
        
        time.sleep(0.3)  # Wait for processing
        
        # Get hourly average again
        response = self.make_request("GET", "/analytics/average-hour")
        self.assertEqual(response.status_code, 200)
        
        analytics_data = response.json()
        self.assertIn("average_temperature", analytics_data)
        self.assertIn("data_source", analytics_data)
        self.assertGreater(analytics_data["readings_count"], 5)  # Should have sufficient readings
        
        # With sufficient recent data, should prefer cache
        print(f"   ‚úÖ Data source: {analytics_data['data_source']}")
        print(f"   ‚úÖ Average temperature: {analytics_data['average_temperature']}¬∞C")
        print(f"   ‚úÖ Readings count: {analytics_data['readings_count']}")
        
        # Verify performance benefit indication
        self.assertIn(analytics_data["data_source"], ["cache", "database"])
        
        # Test multiple requests to verify consistency
        response_times = []
        for i in range(3):
            start_time = time.time()
            response = self.make_request("GET", "/analytics/average-hour")
            end_time = time.time()
            
            self.assertEqual(response.status_code, 200)
            response_times.append((end_time - start_time) * 1000)  # Convert to ms
        
        avg_response_time = sum(response_times) / len(response_times)
        print(f"   ‚ö° Average response time: {avg_response_time:.1f}ms")
    
    # Test 4: Connection Pool Management
    def test_04_connection_pool_management(self):
        """Test connection pool behavior under concurrent load"""
        print("\n4Ô∏è‚É£ Testing connection pool management...")
        
        # Get initial connection pool status
        initial_status = self.get_system_status()
        initial_connections = initial_status["database"]["connection_pool_active"]
        
        print(f"   üîó Initial active connections: {initial_connections}")
        
        # Test concurrent writes
        concurrent_requests = 8  # Test concurrent access
        results = []
        errors = []
        
        def submit_concurrent_reading(thread_id: int):
            """Submit reading from a thread"""
            try:
                temperature = 20 + random.uniform(-5, 5)
                sensor_id = f"concurrent_sensor_{thread_id:02d}"
                
                response = self.submit_reading(temperature, sensor_id)
                results.append({
                    "thread_id": thread_id,
                    "status_code": response.status_code,
                    "success": response.status_code == 200
                })
            except Exception as e:
                errors.append({"thread_id": thread_id, "error": str(e)})
        
        print(f"   üöÄ Starting {concurrent_requests} concurrent requests...")
        
        # Create and start threads
        threads = []
        start_time = time.time()
        
        for i in range(concurrent_requests):
            thread = threading.Thread(target=submit_concurrent_reading, args=(i,))
            threads.append(thread)
            thread.start()
        
        # Wait for all threads to complete
        for thread in threads:
            thread.join()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # Analyze results
        successful_requests = sum(1 for r in results if r["success"])
        failed_requests = len(results) - successful_requests + len(errors)
        
        print(f"   ‚úÖ Successful requests: {successful_requests}/{concurrent_requests}")
        print(f"   ‚è±Ô∏è Total time: {total_time:.2f} seconds")
        print(f"   ‚ö° Average time per request: {(total_time / concurrent_requests) * 1000:.1f}ms")
        
        if failed_requests > 0:
            print(f"   ‚ö†Ô∏è Failed requests: {failed_requests}")
        
        # Verify most requests succeeded (connection pool should handle the load)
        success_rate = successful_requests / concurrent_requests
        self.assertGreater(success_rate, 0.8)  # At least 80% success rate
        
        # Wait for background processing
        time.sleep(0.5)
        
        # Check final connection pool status
        final_status = self.get_system_status()
        final_connections = final_status["database"]["connection_pool_active"]
        total_readings_after = final_status["database"]["total_readings"]
        
        print(f"   üîó Final active connections: {final_connections}")
        print(f"   üìä Total readings stored: {total_readings_after}")
        
        # Verify connection pool constraints
        self.assertGreaterEqual(final_connections, 2)  # Min connections
        self.assertLessEqual(final_connections, 5)     # Max connections
        
        print(f"   ‚úÖ Connection pool within limits: {final_connections} (2-5 range)")
    
    # Test 5: Input Validation and Error Handling
    def test_05_input_validation_and_error_handling(self):
        """Test input validation and system error handling"""
        print("\n5Ô∏è‚É£ Testing input validation and error handling...")
        
        # Test 1: Invalid temperature ranges
        print("   üå°Ô∏è Testing temperature range validation...")
        
        invalid_temperatures = [
            {"temp": -60.0, "sensor": "arctic_sensor", "expected": 400},  # Too cold
            {"temp": 100.0, "sensor": "desert_sensor", "expected": 400},  # Too hot
            {"temp": 150.0, "sensor": "oven_sensor", "expected": 400},    # Way too hot
            {"temp": -100.0, "sensor": "space_sensor", "expected": 400},  # Way too cold
        ]
        
        for test_case in invalid_temperatures:
            response = self.submit_reading(test_case["temp"], test_case["sensor"])
            self.assertEqual(response.status_code, test_case["expected"])
            
            error_data = response.json()
            self.assertIn("detail", error_data)
            print(f"   ‚úÖ Rejected {test_case['temp']}¬∞C: {error_data['detail']}")
        
        # Test 2: Valid edge cases
        print("   üå°Ô∏è Testing valid edge cases...")
        
        valid_edge_cases = [
            {"temp": -49.9, "sensor": "arctic_sensor"},    # Just within range
            {"temp": 59.9, "sensor": "desert_sensor"},     # Just within range
            {"temp": 0.0, "sensor": "freezing_sensor"},    # Freezing point
            {"temp": -50.0, "sensor": "min_sensor"},       # Minimum valid
            {"temp": 60.0, "sensor": "max_sensor"},        # Maximum valid
        ]
        
        for test_case in valid_edge_cases:
            response = self.submit_reading(test_case["temp"], test_case["sensor"])
            self.assertEqual(response.status_code, 200)
            
            result = response.json()
            self.assertEqual(result["temperature"], test_case["temp"])
            print(f"   ‚úÖ Accepted {test_case['temp']}¬∞C")
        
        # Test 3: Invalid request formats
        print("   üìù Testing invalid request formats...")
        
        # Missing temperature
        response = requests.post(f"{self.base_url}/readings", json={
            "sensor_id": "test_sensor"
            # Missing temperature
        })
        self.assertEqual(response.status_code, 422)  # Validation error
        print("   ‚úÖ Rejected request with missing temperature")
        
        # Missing sensor_id
        response = requests.post(f"{self.base_url}/readings", json={
            "temperature": 25.0
            # Missing sensor_id
        })
        self.assertEqual(response.status_code, 422)  # Validation error
        print("   ‚úÖ Rejected request with missing sensor_id")
        
        # Invalid data types
        response = requests.post(f"{self.base_url}/readings", json={
            "temperature": "not_a_number",
            "sensor_id": "test_sensor"
        })
        self.assertEqual(response.status_code, 422)  # Validation error
        print("   ‚úÖ Rejected request with invalid temperature type")
        
        # Test 4: System resilience
        print("   üõ°Ô∏è Testing system resilience...")
        
        # Test with very large limit
        response = self.make_request("GET", "/readings/recent", params={"limit": 1000})
        self.assertEqual(response.status_code, 400)  # Should reject large limits
        print("   ‚úÖ Rejected excessive limit request")
        
        # Test analytics with no data (after clearing)
        requests.delete(f"{self.base_url}/readings/clear")
        time.sleep(0.2)
        
        response = self.make_request("GET", "/analytics/average-hour")
        # Should either return 404 (no data) or handle gracefully
        self.assertIn(response.status_code, [200, 404])
        
        if response.status_code == 404:
            error_data = response.json()
            self.assertIn("detail", error_data)
            print("   ‚úÖ Gracefully handled request with no data")
        else:
            print("   ‚úÖ Handled empty data scenario")
        
        # Test 5: System status accessibility
        print("   üìä Testing system monitoring...")
        
        status_response = self.make_request("GET", "/status")
        self.assertEqual(status_response.status_code, 200)
        
        status_data = status_response.json()
        required_fields = ["status", "database", "cache", "timestamp"]
        
        for field in required_fields:
            self.assertIn(field, status_data)
        
        # Verify status structure
        self.assertIn("total_readings", status_data["database"])
        self.assertIn("connection_pool_active", status_data["database"])
        self.assertIn("size", status_data["cache"])
        self.assertIn("capacity", status_data["cache"])
        
        print(f"   ‚úÖ System status accessible and well-structured")
        print(f"   üìä Current status: {status_data['status']}")

def run_tests():
    """Run all unit tests"""
    # Create test suite
    test_suite = unittest.TestLoader().loadTestsFromTestCase(WeatherStationTestCase)
    
    # Run tests with detailed output
    runner = unittest.TextTestRunner(verbosity=2, stream=None)
    result = runner.run(test_suite)
    
    # Print summary
    print(f"\n{'='*70}")
    print(f"üìä WEATHER STATION TEST SUMMARY")
    print(f"{'='*70}")
    print(f"Tests run: {result.testsRun}")
    print(f"Failures: {len(result.failures)}")
    print(f"Errors: {len(result.errors)}")
    print(f"Success rate: {((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100):.1f}%")
    
    if result.failures:
        print(f"\n‚ùå FAILURES:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print(f"\nüí• ERRORS:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    if not result.failures and not result.errors:
        print(f"\nüéâ ALL TESTS PASSED! üéâ")
        print("\nüîß Core Features Validated:")
        print("‚úÖ Data Storage and Retrieval")
        print("‚úÖ LRU Cache Functionality (100-item capacity)")
        print("‚úÖ Cache-First Analytics Strategy")
        print("‚úÖ Connection Pool Management (2-5 connections)")
        print("‚úÖ Input Validation and Error Handling")
        
        print("\nüéØ Learning Objectives Achieved:")
        print("‚Ä¢ LRU Cache: Capacity management and eviction")
        print("‚Ä¢ Connection Pooling: Concurrent access handling")
        print("‚Ä¢ Time-Series Data: Storage and analytics")
        print("‚Ä¢ Cache-First Queries: Performance optimization")
        print("‚Ä¢ System Resilience: Validation and error handling")
    
    print(f"{'='*70}")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    print("üß™ Weather Station Data Logger Unit Test Suite")
    print("=" * 70)
    print("Make sure the Weather Station API is running:")
    print("python main.py")
    print("=" * 70)
    
    try:
        success = run_tests()
        exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Tests interrupted by user")
        exit(1)
    except Exception as e:
        print(f"\n\nüí• Unexpected error: {e}")
        exit(1)